<!DOCTYPE html>
<html lang="en">
<head>
  <link href="https://fonts.googleapis.com/css?family=Merriweather+Sans:800,400italic|Inconsolata:400|Merriweather:400,400italic" rel="stylesheet" type="text/css">

  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <meta content="width=device-width" name="viewport">
  <title>How to Compute with a Probability Distribution</title>

  
  <meta name="author" content="Alexey Radul" />
  

  <link rel="stylesheet" type="text/css" href="../../../css/erudite.css" />
  <link rel="icon" href="../../../favicon.ico" />
  <link rel="alternate" type="application/rss+xml" title="Conversations Updates -- RSS" href="../../../feed.xml" />
  
</head>

<body>

  <div id="wrapper" class="hfeed">
    <div id="header-wrap">
      <div id="header" role="banner">
        <h1 id="blog-title"><span><a href="../../../" title rel="home">Conversations</a></span></h1>
        <div id="blog-description"></div>
      </div><!--  #header -->
      <div id="access" role="navigation">
        <div class="skip-link"><a href="#content" title></a></div>
      </div><!-- #access -->
    </div><!--  #header-wrap -->

    <div id="container">
      <div id="content" role="main">
        <article class="hentry" itemscope itemtype="http://schema.org/BlogPosting">
  
  <header>
    <h2 class="entry-title" itemprop="name">How <em>to</em> Compute <em>with a</em> Probability Distribution</h2>
  </header>

  <div class="entry-meta">

    <span class="entry-date">
      <abbr class="published">February 15, 2015</abbr>
    </span>
    <span class="author vcard">
      By Alexey Radul
    </span>
  </div>

  <div class="entry-content" itemprop="articleBody">
    <p>What makes a good representation for computing with probability
distributions? The two canonical options are samplers and probability
density functions. Both are valuable; and the relationship between
them turns out to hide two fruitful variations on the idea of a
sampler, that I will call “importanter” and “rejecter”.
The purpose of this essay is to carefully study these four
objects and the interrelations between them, and the light they shed
on the ubiquitous rejection sampling and importance sampling algorithms.</p>
<p>The probabilistic programming system
<a href="http://probcomp.csail.mit.edu/venture/">Venture</a> that I am working on
makes heavy use of the idea that a (computable) probability
distribution is very effectively represented by a stochastic machine
that computes samples from that distribution. A couple months ago I
had the privilege of discussing this topic with <a href="https://twitter.com/ccshan/">Ken
Shan</a>, which conversation
caused me to think through these foundational relationships. Any
elegance in the result is due entirely to Ken; the mistakes are of
course my own.</p>
<p>To make the content computationally concrete, I will spell out what I
am saying in pseudo-Haskell as well as English. Why Haskell? Because
its type system is rich enough to capture the interesting structure
very well. In fact, don’t read the code—read the type signatures.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<h2 id="contents">Contents</h2>
<ul>
<li><a href="#sampling">Sampling</a>
<ul>
<li><a href="#expectation">Expectation</a></li>
<li><a href="#measures">Measures</a></li>
<li><a href="#operations-on-samplers">Operations on Samplers</a></li>
</ul></li>
<li><a href="#densities">Densities</a>
<ul>
<li><a href="#composition-of-densities">Composition of densities</a></li>
</ul></li>
<li><a href="#importance-weighting">Importance Weighting</a>
<ul>
<li><a href="#measuring-importance">Measuring Importance</a></li>
<li><a href="#composition-of-importanters">Composition of Importanters</a></li>
<li><a href="#weighted-expectations">Weighted Expectations</a></li>
<li><a href="#importance-sampling">Importance Sampling</a></li>
<li><a href="#proposals">Proposals</a></li>
<li><a href="#resampling">Resampling</a></li>
</ul></li>
<li><a href="#rejection">Rejection</a>
<ul>
<li><a href="#measuring-rejection">Measuring Rejection</a></li>
</ul></li>
<li><a href="#relationship">Relationship</a></li>
<li><a href="#exchangeable-coupling">Exchangeable Coupling</a></li>
<li><a href="#notes">Notes</a></li>
</ul>
<h2 id="sampling">Sampling</h2>
<blockquote class="pullquote-display">
<p>
A sampler is a machine that represents a probability distribution by its behavior.
</p>
</blockquote>
<p>Let us start our exploration of representations of probability
distributions with the (exact) sampler. A <em>sampler</em> is a machine that
represents a probability distribution by its (random)
behavior:<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<pre><code>type Sampler a  -- A source of random as.</code></pre>
<p>I elide questions of the entropy source; think an infinite stream of
uniformly random bits in the sky. Since I like computation, I will
also require the samplers I think about to terminate with probability
1. A “good” sampler is one that delivers its samples quickly—with
little computation.</p>
<p>Samplers support the following three natural operations (which I will
name by their conventional names):</p>
<pre><code>return :: a -&gt; Sampler a
return x = &quot;sample&quot; by always emitting x, consuming no randomness

fmap :: (a -&gt; b) -&gt; Sampler a -&gt; Sampler b
fmap f sx = sample a b by sampling an a and then calling f on it

join :: Sampler (Sampler a) -&gt; Sampler a
join ssx = sample a (Sampler a) from the input,
           then sample an a from that</code></pre>
<p>These operations make samplers composable.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<p>Exercise: Prove that these definitions for <code>return</code>, <code>fmap</code>, and
<code>join</code> satisfy the <a href="https://en.wikipedia.org/wiki/Monad_%28functional_programming%29#fmap_and_join">Monad
laws</a>
and conclude that samplers form a monad. If you don’t know what I’m
talking about when I say “monad”, don’t worry—for the purposes of
this post, a sufficient intuition is that composing samplers is
“well-behaved”.</p>
<p>Note that there is no performance penalty for composition: the cost of
sampling from the output is a direct consequence of the costs of
running the inputs, without significant overhead.</p>
<h3 id="expectation">Expectation</h3>
<p>If we have a sampler over <span class="math inline">\(\R\)</span> (actually, any vector space, but <span class="math inline">\(\R\)</span>
will do), we can form finite estimates of the expectation (which
estimates are themselves random) by computing some samples and
averaging. In types and code that looks like</p>
<pre><code>finite_expectation :: Int -&gt; Sampler R -&gt; Sampler R
finite_expectation n sx = fmap average (replicateM n sx)</code></pre>
<p>Theorem (<a href="https://en.wikipedia.org/wiki/Law_of_large_numbers">Law of Large Numbers</a>):
For any sampler <code>sx :: Sampler R</code>, as <span class="math inline">\(n \to \infty\)</span>, the finite
expectations <code>finite_expectation n sx</code> converge (as distributions) to
<code>return mean_sx :: Sampler R</code> for some number <code>mean_sx</code>.</p>
<p>The constant <code>mean_sx</code> is of course the expected value of the
distribution given by the sampler <code>sx</code>. The law of large numbers
gives us licence to call it <em>the</em> expected value of <code>sx</code>. By abuse
of notation, we can write that idea down as (well-typed!) pseudo-code:</p>
<pre><code>expect :: Sampler R -&gt; R
expect sx = mean_sx where
  return mean_sx = infinite_limit (\n -&gt; finite_expectation n sx)</code></pre>
<h3 id="measures">Measures</h3>
<p>Once we have the idea of expectations, a sampler for any type <code>a</code> gives rise to a
<a href="https://en.wikipedia.org/wiki/Measure_%28mathematics%29">measure</a> over
the set <span class="math inline">\(A\)</span> of all objects of type <code>a</code>. This links our computational objects
to the standard mathematical foundations of probability theory.</p>
<p>Intuitively, the size of a subset under this measure is the
probability that the sampler produces an object from that subset. Formally,
for <code>sx :: Sampler a</code>, and any subset <span class="math inline">\(S \subset A\)</span> given by an
indicator function <span class="math inline">\(f_S : A \to \{0,1\}\)</span>, we can define <span class="math inline">\(\mu(S)\)</span> as
the expected value of composing the sampler with the indicator function:</p>
<p><span class="math display">\[ \mu(S) = \texttt{expect (fmap f sx)}. \]</span></p>
<p>Exercise: Prove that <span class="math inline">\(\mu\)</span> given by the above definition is a
<a href="https://en.wikipedia.org/wiki/Probability_measure">probability measure</a>.</p>
<p>Exercise: Prove that integration with respect to <span class="math inline">\(\mu\)</span> is expectation
under the sampler:</p>
<p><span class="math display">\[ \forall (c:A \to \R), \int c d\mu = \texttt{expect (fmap c sx)}. \]</span></p>
<p>Insofar as probability measures are accepted as a reasonable
definition of “what a probability distribution is”, the two above
facts mean that a sampler can validly be said to represent
the probability distribution on its outputs.</p>
<h3 id="operations-on-samplers">Operations <em>on</em> Samplers</h3>
<p>How well do samplers implement the operations we like to perform on
probability distributions?</p>
<ul>
<li><p>Joint distributions: If the sampler <code>sx :: Sampler a</code> represents the
distribution <span class="math inline">\(p(a)\)</span>, and the function <code>f :: a -&gt; Sampler b</code>
represents the conditional distribution <span class="math inline">\(p(b|a)\)</span>, then getting a
sample from the joint distribution consists of drawing a sample from
<code>sx</code>, applying <code>f</code> to get a sampler for <code>b</code>s, drawing a sample from
that, and emitting the pair:</p>
<pre><code>joint :: Sampler a -&gt; (a -&gt; Sampler b) -&gt; Sampler (a, b)
joint sx f = do
  a &lt;- sx
  b &lt;- f a
  return (a, b)</code></pre></li>
<li><p>Marginal distributions: If we have a sampler that represents the
probability distribution <span class="math inline">\(p(a,b)\)</span>, then drawing a sample from the
marginal distribution <span class="math inline">\(p(a)\)</span> is just drawing a sample from the joint
and throwing away the unneeded component:</p>
<pre><code>marginal :: Sampler (a, b) -&gt; Sampler a
marginal = fmap fst</code></pre></li>
<li><p>Conditional distributions: However, a sampler for <span class="math inline">\(p(a,b)\)</span> does not
easily lend itself to a sampler for the conditional <span class="math inline">\(p(b|a=x)\)</span>.
Conditional distributions are hard.</p>
<pre><code>conditional :: Sampler (a, b) -&gt; a -&gt; Sampler b
conditional = ???</code></pre></li>
</ul>
<p>Exercise: Prove that the above two constructions actually work, namely
that <code>joint sx f</code> represents the correct joint probability measure and
<code>marginal sxy</code> represents the correct marginal probability measure.</p>
<p>The lack of natural samplers for conditioning is unfortunate, because
conditioning is an important operation. Conditioning is arguably
<em>the</em> operation that gives probability theory its practical
significance, since it is the operation that poses the causal
inference problems we need probability for: “given a cause-and-effect
model <span class="math inline">\(p(a,b)\)</span>, and given that effect <span class="math inline">\(A\)</span> happened, what causes <span class="math inline">\(B\)</span>
for it are probable?”</p>
<h2 id="densities">Densities</h2>
<p>The other common representation for probability distributions is the
density function<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. A <em>density function</em> (or just density
for short) is a way to evaluate how “dense” a probability distribution
(measure) is at some particular value. Such an evaluation is perforce
relative to some other measure, which is taken to represent our notion
of “uniformly dense” (even though it can really be pretty much any
measure on the same space).</p>
<pre><code>type Density a = a -&gt; R  -- positive only; the base measure is implicit</code></pre>
<p>Given a base measure <span class="math inline">\(\mu\)</span> on <code>a</code>, a density <code>d :: Density a</code>
defines a measure <span class="math inline">\(\mu_d\)</span> by</p>
<p><span class="math display">\[ \mu_d(S \subset A) = \int_S d d\mu. \]</span></p>
<p>Exercise: Prove that the integration rule for <span class="math inline">\(\mu_d\)</span> is</p>
<p><span class="math display">\[ \forall (c:a \to \R), \quad \int c d\mu_d = \int d \cdot c d\mu, \]</span>
where the multiplication on the right hand side is taken pointwise.
This is the expected value of the function <span class="math inline">\(c\)</span> under the probability
distribution given by <span class="math inline">\(d\)</span>.</p>
<p>Corollary: If <span class="math inline">\(\mu\)</span> is a probability measure, then <span class="math inline">\(\mu_d\)</span> is also,
provided <span class="math inline">\(\int_A d d\mu = 1\)</span>.</p>
<p>Exercise: Prove that <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\mu_d\)</span> determine the density function
uniquely (up to the usual caveats of continuous analysis):</p>
<p><span class="math display">\[ d(a) = \lim_{\mu(S) \to 0} \frac{\mu_d(S)}{\mu(S)} \qquad \textrm{for } a \in S \subset A.  \]</span>
Not all pairs <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\mu_d\)</span> give rise to finite density functions
<span class="math inline">\(d\)</span>, but exploring that topic would take us too far afield.</p>
<blockquote class="pullquote-display">
<p>
Both a density and a sampler give a probability distribution, but
they offer operationally different information about it.
</p>
</blockquote>
<p>Both a <code>Density a</code> and a <code>Sampler a</code> give a measure on <code>a</code>, but they
offer operationally different information about it. The sampler gives
a computational mechanism for drawing examples, the distribution of
which obeys the measure. The density function gives a computational
mechanism for evaluating any given object under the measure.
Recovering either of these operations from the other requires
integration (either with respect to the base measure of the density or
the measure given by the sampler), which cannot in general be done
cheaply and exactly.</p>
<p>Consequently, it can be useful to carry both a sampler and a density
for the same measure:</p>
<pre><code>type Dist a = (Sampler a, Density a)  -- for the same measure
  -- the base measure of the density is implicit</code></pre>
<p>Well-studied probability distributions typically have both efficient
samplers and efficient density functions, hence the name <code>Dist</code> for
the type.</p>
<h3 id="composition-of-densities">Composition <em>of</em> Densities</h3>
<p>Densities also technically obey the monad laws, but only if one is
willing to take integrals (or sums in the discrete case). Since
integrals are awkward to express in code, I will record them in math.
Also, the integrals make more sense at the level of measures; the
actual densities can be derived as limits thereof as usual.</p>
<pre><code>return :: a -&gt; Density a
fmap :: (a -&gt; b) -&gt; Density a -&gt; Density b
join :: Density (Density a) -&gt; Density a</code></pre>
<p><span class="math display">\[ \begin{eqnarray*}
 \mu_{\texttt{return x}}(S \subset A) &amp; = &amp; \begin{cases} 1 \textrm{ if } \texttt{x} \in S \\ 0 \textrm{ otherwise} \end{cases}, \\
 \mu_{\texttt{fmap f d}}(S \subset B) &amp; = &amp; \int_{f^{-1}(S)} 1\ d\mu_{\texttt{d}}, \\
 \mu_{\texttt{join dd}}(S \subset A) &amp; = &amp; \int_{\textrm{densities } d \textrm{ on } A} \left( \int_S 1 d \mu_d\right) d \mu_{\textrm{dd}}.
\end{eqnarray*} \]</span></p>
<p>Exercise: Prove that the above operations are well-formed, that is
that if the arguments represent probability distributions then the
results do too.</p>
<p>Exercise: Prove that densities obey the monad laws with the above
operations.</p>
<p>How well do densities perform the operations we like on probability
distributions?</p>
<ul>
<li><p>Joint distributions: If <span class="math inline">\(p(a)\)</span> is represented by a density, and <span class="math inline">\(p(b|a)\)</span>
is represented by a function from <code>a</code> to a density, then the joint
distribution <span class="math inline">\(p(a, b)\)</span> is represented by the product:</p>
<pre><code>joint :: Density a -&gt; (a -&gt; Density b) -&gt; Density (a, b)
joint dx fxdy (x,y) = dx x * fxdy x y</code></pre></li>
<li><p>Marginal distributions: Marginal distributions are actually the
place where the integrals in the monad laws come from. If
<span class="math inline">\(p(a,b)\)</span> is represented by a density, then to compute the density
of <span class="math inline">\(p(a)\)</span> it is necessary to integrate the density function over
all possible <span class="math inline">\(b\)</span> (with respect to the projection of the base
measure):</p>
<pre><code>marginal :: Density (a, b) -&gt; Density a
marginal dxy x = -- integral over y of dxy (x,y)</code></pre></li>
<li><p>Conditional distributions: Conditional distributions are the place
where densities show their true worth—taking conditional densities
is just currying:</p>
<pre><code>conditional :: Density (a, b) -&gt; a -&gt; Density b
conditional dxy x y = dxy (x,y)  -- unnormalized</code></pre></li>
</ul>
<p>There is actually an important subtlety in the last of these, which is
that the result <code>conditional dxy x</code> will not integrate to 1 over <code>y</code>
unless we scale it by the appropriate integral. This is unfortunate,
because that integral is all too often intractable, but even an
unnormalized density is better than nothing.</p>
<p>Exercise: Prove that these formulas are correct, namely that the
results of <code>joint</code>, <code>marginal</code>, and <code>conditional</code> actually represent
the respective joint, marginal, and conditional measures (in the
latter case, up to multiplication by a constant). In the case of
<code>joint</code>, the base measure on <code>b</code> should not depend on the value
passed to the function <code>fxdy</code>.</p>
<blockquote class="pullquote-display">
<p>
Much of the theory of Bayesian inference is a search for various
ways to turn a density into a sampler for the same distribution.
</p>
</blockquote>
<p>Conditioning is why densities are interesting. But samplers are nicer
to compute with. Is there a way to get from a density to a sampler
for the same distribution? Much of the theory of Bayesian inference
is a search for various ways to do that with acceptable performance
and acceptable degree of approximation.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> But let us start
with basics.</p>
<h2 id="importance-weighting">Importance Weighting</h2>
<p>So, suppose we have a <code>Density a</code> and we want something like a sampler
for the same distribution. What can we do? Well, the density is
against a base measure, which we presumably understand. So we can
perhaps draw samples from the base measure and weight them by the
density. What would that get us? Eventually it will get us to the
ubiquitous <a href="https://en.wikipedia.org/wiki/Importance_sampling">importance
sampling</a> and
<a href="https://en.wikipedia.org/wiki/Rejection_sampling">rejection sampling</a>
algorithms, but let’s take it slow and think through each step as it
comes.</p>
<p>So, weighted samples:</p>
<pre><code>type Weight = R  -- should be non-negative
type Importanter a = Sampler (a, Weight)

weighted :: Sampler a -&gt; Density a -&gt; Importanter a
weighted sx dx = do
  x &lt;- sx
  return (x, dx x)</code></pre>
<p>What is this object that we get as a result? An importanter over <code>a</code>
is a machine that emits random values of type <code>a</code> together with the
weights (which are real numbers) those values should be given.
How meaningfully does an importanter represent a probability
distribution?</p>
<h3 id="measuring-importance">Measuring Importance</h3>
<p>We can capture the idea that the samples emitted by an importanter
“should be” taken with the grains of salt given by the weights, by
defining the measure on <code>a</code> that an importanter gives to take that
information into account.</p>
<p>Formally, consider <code>ix :: Importanter a</code>. Being a sampler, <code>ix</code>
defines a measure <span class="math inline">\(s\)</span> on the set of pairs <span class="math inline">\(A \times \R\)</span>. For any
subset <span class="math inline">\(S \subset A\)</span> with indicator function <span class="math inline">\(f_S\)</span>, we can define the
weight of <span class="math inline">\(S\)</span> under <span class="math inline">\(s\)</span> as</p>
<p><span class="math display">\[ W(S) = \int_{(x,w)} w f_S(x) ds, \]</span>
which is the expected weight of elements of <span class="math inline">\(S\)</span> generated by <code>ix</code>.
Then we can define <span class="math inline">\(\mu\)</span> on <span class="math inline">\(A\)</span> as the fraction of the total expected
weight contained in <span class="math inline">\(S\)</span>:</p>
<p><span class="math display">\[ \mu(S \subset A) = \frac{W(S)}{W(A)}, \]</span>
provided the denominator is finite and positive.</p>
<p>Exercise: Prove that <span class="math inline">\(\mu\)</span> is a probability measure if <span class="math inline">\(s\)</span> is
and <span class="math inline">\(0 &lt; W(A) &lt; \infty\)</span>.</p>
<p>Exercise: Prove that if <code>dx :: Density a</code> is a density and <code>sx :: Sampler a</code> is a sampler for the base measure of <code>dx</code>, then <code>weighted sx dx :: Importanter a</code> is an importanter representing the same
probability distribution as <code>dx</code>.</p>
<p>Exercise: Prove that the integration rule under <span class="math inline">\(\mu\)</span> is given by</p>
<p><span class="math display">\[ \forall (c:A \to \R), \quad \left(\int c d\mu\right) W(A)
  = \int \texttt{comp c } ds, \]</span>
where</p>
<pre><code>comp :: (a -&gt; R) -&gt; (a, R) -&gt; R
comp c (x, weight) = (c x) * weight</code></pre>
<p>This integration rule formalizes the idea that to make conclusions
about <span class="math inline">\(\mu\)</span> based on being able to compute with <span class="math inline">\(s\)</span>, we have to weight
every <code>x</code> we get out of <span class="math inline">\(s\)</span> by the weight it came with, and discount
our overall conclusions by the overall weight <span class="math inline">\(W(A)\)</span>.</p>
<h3 id="composition-of-importanters">Composition <em>of</em> Importanters</h3>
<p>is enough like composition of samplers that I omit the discussion to
save space.</p>
<h3 id="weighted-expectations">Weighted Expectations</h3>
<p>The integration rule for the measure denoted by an importanter
tells us how to compute expectations with weighted samples, which
conveniently agrees with what one would expect:</p>
<pre><code>finite_weighted_expectation :: Int -&gt; Importanter R -&gt; Sampler R
finite_weighted_expectation n ix = fmap w_avg $ replicateM n ix where
  w_avg :: [(R, Weight)] -&gt; R
  w_avg samples = (sum $ map times samples) / (sum $ map snd samples)
  times (x, w) = x * w</code></pre>
<p>Theorem (Law of Large Numbers with weights): For any importanter <code>ix :: Importanter R</code>, as
<span class="math inline">\(n \to \infty\)</span>, the finite weighted expectations
<code>finite_weighted_expectation n ix</code> converge (as distributions) to
<code>return mean_ix :: Sampler R</code> where the constant <code>mean_ix</code> is the
expected value of the distribution on <span class="math inline">\(\R\)</span> denoted by the importanter
<code>ix</code>.</p>
<p>This theorem justifies the definition</p>
<pre><code>weighted_expect :: Importanter R -&gt; R
weighted_expect ix = mean_ix where
  return mean_ix = infinite_limit (\n -&gt; finite_weighted_expectation n ix)</code></pre>
<h3 id="importance-sampling">Importance Sampling</h3>
<p>Getting a (terminating, exact) sampler out of an importanter, however,
is more complicated. The trouble is
that no matter how many times we’ve run our importanter, it’s possible
that the next run will produce a new value with a huge weight, and
throw off all our previous conclusions. But let’s take that one step
at a time.</p>
<blockquote class="pullquote-display">
<p>
No matter how many weighted samples one has drawn, the next one might
have such a huge weight that it throws off all previous conclusions.
</p>
</blockquote>
<p>There is of course an obvious and computationally efficient way to get
some sampler for <code>a</code> out of an importanter over <code>a</code>—just drop the
weights:</p>
<pre><code>importance_approximation :: Importanter a -&gt; Sampler a
importance_approximation = fmap fst</code></pre>
<p>The trouble is, of course, that the sampler we get does not sample
from the distribution the importanter denotes—unless the weights are
all equal. And indeed, the closer the weights are to equal, the
better an approximation it is to just drop them. It turns out
that if we define</p>
<pre><code>weight_distribution :: Importanter a -&gt; Sampler Weight
weight_distribution = fmap snd</code></pre>
<p>then we get the</p>
<p>Theorem: The quality of the <code>importance_approximation</code> goes
as the quality of the approximation <code>return . expect</code> to the
<code>weight_distribution</code>.</p>
<p>So a “good” importanter is one that uses little computation to run and
produces weights concentrated around one value.</p>
<h3 id="proposals">Proposals</h3>
<p>Above, we constructed an <code>Importanter a</code> out of a <code>Density a</code> by
drawing samples from the base measure and weighting them by the
density. The trouble is that if the density is peaky, this will yield
an importanter with a wide spread of weights, which may not be very
efficient. If we can (efficiently) account for some of that variation
by drawing those samples from some other probability distribution,
that is perhaps closer to the target, we may be able to get a better
importanter.</p>
<p>To wit, we can use any <code>Dist a</code> (whose density has the same base
measure as the target) as a <em>proposal distribution</em> whose samples we
can weight to make an importanter. The weight of a proposal is its
value under our goal density, divided by its value under the proposal
density.</p>
<pre><code>proposal_to_importanter :: Dist a -&gt; Density a -&gt; Importanter a
proposal_to_importanter (propose, prop_density) target_density = do
  sample &lt;- propose
  let d_target = target_density sample
      d_prop = prop_density sample
  return (sample, d_target / d_prop)</code></pre>
<p>Theorem: Given any proposal distribution <code>xs</code> and a target density
<code>target</code>, the importanter <code>proposal_to_importanter xs target</code> denotes
the same measure on <code>a</code> as the <code>target</code>, provided:</p>
<ul>
<li>the two densities are with respect to the same base measure on <code>a</code>
(but it doesn’t matter what that base measure is!), and</li>
<li>and their ratio at every <code>a</code> is finite (that is, <code>xs</code> has a positive
density at any <code>a</code> with positive density under <code>target</code>).</li>
</ul>
<p>The division of densities also amounts to changing the base measure of
the target density to be the measure denoted by the sampler of the
proposal distribution.</p>
<p>A “good” proposal distribution for a given target is one that leads to
a good importanter—ideally, the proposal (and the density ratio) are
efficient to evaluate, but at least as importantly we want the density
ratio to be concentrated around the mean, rather than varying widely.
For that, we want the proposal distribution to be close to the target,
and in particular not to under-cover any region too severely (because
that can lead to very large weights). In the limit where the proposal
distribution is exactly the target distribution, the weights always
come out exactly 1.</p>
<h3 id="resampling">Resampling</h3>
<p>Even if we can’t find a good proposal distribution,
we can trade work for a more concentrated weight distribution. There
is a universal trick called <em>resampling</em> for trading computation for
improving the importance approximation of any importanter. It consists of computing <span class="math inline">\(n\)</span>
weighted samples, picking one with probability proportional to the
weights, and emitting it with the combined weight of all the samples you
drew. In a sense, that one sample summarizes the information gained
from the <span class="math inline">\(n\)</span> runs of the importanter. In code:</p>
<pre><code>finite_resample :: Int -&gt; Importanter a -&gt; Importanter a
finite_resample n ix = do
  samples &lt;- replicateM n ix
  result &lt;- weighted_select samples
  return (result, sum $ map snd samples)
  where weighted_select :: [(a, Weight)] -&gt; Sampler a
        -- picks an element from the given list with probability
        -- proportional to its weight</code></pre>
<p>Exercise: Prove that for any <span class="math inline">\(n &gt; 0\)</span> and any <code>ix :: Importanter a</code>,
the measure on <code>a</code> given by <code>finite_resample n ix</code> is the same as the
measure given by <code>ix</code> itself.</p>
<p>Exercise: Prove that for fixed <code>ix :: Importanter a</code>, as <span class="math inline">\(n\)</span>
increases, the <code>weight_distribution</code> of <code>finite_resample n ix</code>
concentrates, thereby improving the <code>importance_approximation</code>.</p>
<p>Theorem: In the limit as <span class="math inline">\(n\)</span> tends to <span class="math inline">\(\infty\)</span>, the distribution
denoted by the sampler <code>importance_approximation $ finite_resample n ix</code> converges to the distribution denoted by the importanter <code>ix</code>.</p>
<p>Exercise: Implement the resampling idea without knowing <span class="math inline">\(n\)</span> in advance
and without consuming intermediate storage that is linear in <span class="math inline">\(n\)</span>.</p>
<pre><code>rolling_resample :: Importanter a -&gt; [Importanter a]
-- the nth element of rolling_resample ix should be equivalent to
-- finite_resample n ix</code></pre>
<p>The trick is that weighted selection is associative.</p>
<p>Why might resampling be of use? That is, why throw out the samples we
(presumably) spent so much computation on instead of providing all of
them? Because actually, fewer samples will require less computation
downstream; and the resampling rule will tend to pick samples with
large weight, so the samples that are thrown away were less important
anyway.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<h2 id="rejection">Rejection</h2>
<p>Having studied importance, let us turn to another foundational method
of creating samplers for new probability distributions.
<a href="https://en.wikipedia.org/wiki/Rejection_sampling">Rejection
sampling</a> is the
probabilist’s name for “generate and test”—make up an object, and if it is
“good”, keep it, otherwise try again. The great advantage of
rejection sampling is how little information it requires to operate;
little enough that it can serve as a definition for the idea of
conditional probability.</p>
<p>We can package up the generation part and the test part in a single
intermediate object that we can reason about as a whole:</p>
<pre><code>type Rejecter a = Sampler (Maybe a)</code></pre>
<p>The way to read this is that a <code>Rejecter</code> over <code>a</code> is a sampler that
can fail: it either successfully produces <code>Just</code> an <code>a</code>, or produces a
sentinel value called <code>Nothing</code> that indicates failure. The
relationship between rejecters and samplers is that one can recover a
sampler by trying a rejecter repeatedly until it succeeds:<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a></p>
<pre><code>rejection :: Rejecter a -&gt; Sampler a
rejection r = fmap head $ fmap catMaybe $ replicateM r</code></pre>
<p>Computing expectations from a rejecter consists of turning it into a
sampler and computing expectations.</p>
<h3 id="measuring-rejection">Measuring Rejection</h3>
<p>The link to measure theory lets us directly define which
distribution over <code>a</code> a given <code>Rejecter a</code> represents, without having
to appeal to the <code>rejection</code> algorithm to be definitional (and
therefore without having to re-analyze its behavior whenever the idea
of rejection appears):</p>
<p>By virtue of being a sampler, a rejecter denotes a measure over
<code>Maybe a</code>. We can associate a measure over <code>a</code> with it by
saying that the size of any subset <span class="math inline">\(S\)</span> is the size of <span class="math inline">\(S\)</span> viewed as a
subset of <span class="math inline">\(A \cup \{\texttt{Nothing}\}\)</span>, scaled up by dividing it by
the probability of the rejecter accepting (provided that probability
is positive).</p>
<p>Formally, given a <code>xs :: Rejecter a</code>, let <span class="math inline">\(s\)</span> be the measure on <code>Maybe a</code> defined by <code>xs</code>. For any subset <span class="math inline">\(S \subset A\)</span>, we can abuse
notation to define <span class="math inline">\(\texttt{Just } S\)</span> to be the set of objects of type
<code>Maybe a</code> that are <code>Just</code> some element of <span class="math inline">\(S\)</span>. Then we can set</p>
<p><span class="math display">\[ \mu(S) = \frac{s(\texttt{Just } S)}{s(\texttt{Just } A)}, \]</span>
provided the denominator is positive.<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></p>
<p>Exercise: Prove that <span class="math inline">\(\mu\)</span> is a probability measure whenever the
acceptance probability <span class="math inline">\(s(\texttt{Just } A)\)</span> is positive.</p>
<p>Exercise: Prove that integration under <span class="math inline">\(\mu\)</span> is given by the
rule</p>
<p><span class="math display">\[ \forall (c:A \to \R), \quad \left(\int c d\mu\right) s(\texttt{Just } A)
  = \int \texttt{comp c } ds, \]</span>
where</p>
<pre><code>comp :: (a -&gt; R) -&gt; Maybe a -&gt; R
comp c (Just x) = c x
comp c Nothing  = 0</code></pre>
<p>One interpretation of this rule is that to turn the measure <span class="math inline">\(s\)</span> on
<code>Maybe a</code> into the measure <span class="math inline">\(\mu\)</span> on <code>a</code>, we just pretend that <code>Maybe a</code> was <code>a</code>, except we demand that all users of the <code>Maybe a</code> interpret
<code>Nothing</code> results as “no effect” (which is what zero does for
integration), and scale their conclusions by the inverse of the
probability of acceptance. In a manner of speaking, we moved the
rejection into the continuation.</p>
<p>Exercise: Prove the soundness of the <code>rejection</code> algorithm. To wit,
for any <code>xs :: Rejecter a</code> that terminates with probability 1 and accepts
with positive probability, prove that</p>
<ul>
<li><p>the sampler <code>rejection xs</code> terminates with probability 1, and</p></li>
<li><p>the measure <span class="math inline">\(\mu_1\)</span> on <code>a</code> given by <code>rejection xs</code> is the same as
the measure <span class="math inline">\(\mu_2\)</span> on <code>a</code> given directly by <code>xs</code> through the above
definition.</p></li>
</ul>
<p>Note: The expected number of times the <code>rejection</code> algorithm will invoke
the rejecter is the inverse of the probability of acceptance. Thus, a
“good” rejecter for <span class="math inline">\(\mu\)</span> is one that uses little computation per
attempt, and accepts with reasonably high probability, so that
applying <code>rejection</code> to it produces a good sampler.</p>
<h2 id="relationship">Relationship</h2>
<p>Now it is time to tie these concepts together.</p>
<blockquote class="pullquote-display">
<p>
If we have an upper bound on the weights, we can recover an exact
sampler by converting those weights into probability of acceptance.
</p>
</blockquote>
<p>The best we could do with just an importanter is to resample it some
number of times and hope the resulting approximation to the
distribution that importanter represents is good enough. With a
little more information, though, it is possible to turn an importanter
into a rejecter (and therefore a sampler) denoting exactly the same measure.
To wit, if we somehow (analytically?) know
an upper bound on the weights produced by some importanter, we can
turn it into a rejecter that produces samples from the same
distribution:</p>
<pre><code>type WeightBound = Double

importanter_to_rejecter :: WeightBound -&gt; Importanter a -&gt; Rejecter a
importanter_to_rejecter bound xs = do
  (sample, weight) &lt;- xs
  u &lt;- unit_random
  if u * bound &lt; weight then
    return $ Just sample
  else
    return Nothing</code></pre>
<p>The intuition for this algorithm is that it translates the weight that
should be attached to any given <code>a</code> that comes out of <code>xs</code> into the
probability that this particular <code>a</code> will be accepted by the test. In
order to do that coherently, though, an upper bound on weights is
needed, to make sure that all the probabilities are scaled correctly.
If the bound not tight, the resulting rejecter will accept less often
than it might.</p>
<p>Theorem: If <code>bound</code> is larger than any weight <code>xs :: Importanter a</code>
can ever return, then <code>importanter_to_rejecter bound xs</code> denotes the
same measure on <code>a</code> as <code>xs</code> does.</p>
<p>Conjecture: If the integral of returnable weights that are above the
<code>bound</code> is small, then <code>importanter_to_rejecter bound xs</code> denotes a
measure close to the measure denoted by <code>xs</code>.</p>
<p>Thus a “good” importanter for which one also knows a tight upper bound
on the returned weights leads to a “good” rejecter. The exactness
provided by rejection comes at a price—one needs to have an upper
bound, and the rejecter will perform worse if one’s bound is overly
conservative.</p>
<p>Now we have all the pieces to understand the standard names from the
field. Importance sampling is usually presented as the composition
of proposal weighting, resampling some number of times, and dropping
the weights:</p>
<pre><code>importance_sampling :: Int -&gt; Dist a -&gt; Density a -&gt; Sampler a
importance_sampling n prop target =
  importance_approximation $     -- the result is approximate
  finite_resample n $
  proposal_to_importanter prop target</code></pre>
<p>Rejection sampling is usually presented as a different composition,
of proposal weighting, converting weights into probabilities of
acceptance, and looping until an acceptable sample is generated:</p>
<pre><code>rejection_sampling :: WeightBound -&gt; Dist a -&gt; Density a -&gt; Sampler a
rejection_sampling bound prop target =
  rejection $
  importanter_to_rejecter bound $
  proposal_to_importanter prop target</code></pre>
<p>I find the decomposition into distinct <code>Sampler</code>s, <code>Rejecter</code>s, and
<code>Importanter</code>s more aesthetic—and tending toward greater parsimony
and generality of analysis.</p>
<h2 id="exchangeable-coupling">Exchangeable Coupling</h2>
<p>And now for something completely different that this view sheds light
on.</p>
<p>The phenomenon of <a href="https://en.wikipedia.org/wiki/Exchangeable_random_variables">exchangeable
sequences</a>
arises from there being two different ways to get a <code>Sampler [a]</code> from
(a desired length and) a <code>Sampler (Sampler a)</code>. That is, if you have
a machine that makes random machines that make random objects, and you
want a random sequence of objects, you have options, and they are not
the same.</p>
<p>A distribution on length-<span class="math inline">\(n\)</span> lists <code>xs :: Sampler [a]</code> is said to be
<em>independent and identically distributed (IID) with distribution <code>x</code></em> if
<code>x :: Sampler a</code> and <code>xs = replicateM n x</code>. That is, as the name says,
each object was generated independently from the others from the same known
distribution.</p>
<p>A distribution on length-<span class="math inline">\(n\)</span> lists is said to be <em>exchangeable</em> if all
permutations of a given list are equiprobable under it. All IID
distributions are exchangeable, but not vice versa.</p>
<p>So, if you have a <code>Sampler (Sampler a)</code> and you want independent <code>a</code>s,
you can make a new machine for each object, and use it once:</p>
<pre><code>independently :: Int -&gt; Sampler (Sampler a) -&gt; Sampler [a]
independently n xss = replicateM n $ join xss</code></pre>
<p>makes an IID sampler with element distribution <code>join xss</code> (in
probabilist-speak, the one-element distribution marginalizing out the
machines).</p>
<p>On the other hand, you could also make just one machine, and generate
all your samples from it:</p>
<pre><code>exchangeably :: Int -&gt; Sampler (Sampler a) -&gt; Sampler [a]
exchangeably n xss = join $ fmap (replicateM n) xss
                -- = xss &gt;&gt;= (replicateM n)</code></pre>
<p>This sampler is not IID,<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> but is still
exchangeable.<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></p>
<p>Theorem (de-Finetti): All exchangeable distributions can (in principle) be
represented as an application of <code>exchangeably</code> to some distribution
over distributions.</p>
<p>Typical probabilistic programming languages make the difference
between <code>independently</code>, <code>exchangeably</code>, and <code>fmap (replicateM n)</code> a
pain to think about, because they implicitly <code>join</code> everywhere, so one
has to write one’s code carefully to get the effect one wants.</p>
<h2 id="thanks">Thanks</h2>
<p>to Tanya Khovanova, Alex Plotnick, and David Wadden for reading drafts
of this.</p>
<h2 id="notes">Notes</h2>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/javascript">
MathJax.Hub.Config({
  TeX: {
    Macros: {
      R: "{\\mathbb{R}}",
      eps: "\\varepsilon"
    },
    equationNumbers: { autoNumber: "AMS" },
    noErrors: { disabled: true },
  }
});
</script>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>If you don’t know Haskell, don’t worry: I will say
everything in English first. You will just have to take my word that
there are simple algorithms. Here is a quick glossary for
how to interpret the type signatures, so you can follow the shape
of the argument:</p>
<ul>
<li><p><code>--</code> (two hyphens) begins a comment, which continues to the end
of the line.</p></li>
<li><p><code>::</code> (two colons) means “of type” or “has type”. It says that the
expression on the left has the type given on the right.</p></li>
<li><p><code>-&gt;</code> (rightward arrow) is an infix type operator meaning “function”.
That is, <code>Foo -&gt; Bar</code> is a function taking an object of type <code>Foo</code>
and returning one of type <code>Bar</code>. The arrow associates to the right:
<code>Foo -&gt; Bar -&gt; Baz</code> is <code>Foo -&gt; (Bar -&gt; Baz)</code>, which is a function
taking a <code>Foo</code> and returning a function that takes a <code>Bar</code> and
produces a <code>Baz</code>. Such a beast is operationally equivalent to
a binary function that takes a <code>Foo</code> and a <code>Bar</code> and produces
a <code>Baz</code>, and Haskell automatically applies the equivalence whichever
way is most convenient.</p></li>
<li><p>(whitespace) is type constructor application. For example,
one writes <code>Set Integer</code> to denote the type of sets of integers.
So a function from sets of integers to sets of floating point
numbers would have type <code>Set Integer -&gt; Set Double</code>.</p></li>
<li><p>Haskell type signatures can have variables in them.
<code>Set a -&gt; Set a</code> means “a function from sets of anything to sets
of the same thing.” Actually, it means something stronger than
that: the function is taken to be <a href="https://en.wikipedia.org/wiki/Parametric_polymorphism">parametrically
polymorphic</a>,
which is to say it can’t manipulate the individual objects of
type <code>a</code>, but operate only on the set.</p></li>
<li><p><code>[]</code> (square brackets) mean “list of” in Haskell.</p></li>
<li><p><code>(,)</code> (comma-separated list in round brackets) is for tuples.
The components of 2-tuples are accessed by the functions <code>fst</code>
and <code>snd</code>.</p></li>
<li><p>In the code, (whitespace) is function application. In Haskell,
one writes <code>f x</code> to mean “apply f to x”. This choice is natural
for a functional language, where one is applying functions all
the time, but can be a bit confusing to someone who is not used
to juxtaposition signifying that. This operator has the highest
precedence: <code>f x + 4</code> is “apply f to x, then add 4”, not “apply
f to x+4”. There is also the <code>$</code> operator, which is function
application but with the lowest precedence, so <code>f $ x + 4</code> is
“apply f to x+4”.</p></li>
</ul>
<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></li>
<li id="fn2"><p>Samplers are different from random variables as
traditionally defined. One of the formulations of traditional random
variables is “(measurable) functions from a probability space”.
Samplers are also functions from a probability space, namely the space
of unbounded numbers of uniform random bits. The difference is that
traditional random variables can be functions from the same
probability space, and thus can exhibit dependence; whereas I treat
Samplers as getting independent random bits every time they are
called. The two formulations are equi-expressive (at least if
restricted to computable situations): any system of random variables
can be modeled as a big Sampler for their joint distribution; and any
invocation of a Sampler can be viewed as a system of random variables
(one per intermediate value in the Sampler’s computation).<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>In case the <code>join</code> operation looks a bit strange, imagine
randomly choosing a coin and then flipping it once. If the coins may
have different weights, that’s a probability distribution (the choice)
over probability distributions (the possible biases of the flip).
<code>join</code> just tells us that we can view that compound process as a
single probability distribution over heads/tails outcomes.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>One also talks about <a href="https://en.wikipedia.org/wiki/Cumulative_distribution_function">cumulative distribution
functions</a> (CDFs)
when one talks about probability distributions over the real numbers,
but I won’t bother because a CDF is just the integral of the density,
so carries (more of) the same sort of information. Not all of the
subsequent discussion applies, because there is a good way to recover
a sampler from a CDF, but CDFs are also much less commonly available
than densities.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>That is, sampling from a different distribution that is
easier to sample from but approximates the distribution given by the
density; or, in some cases, sampling from a different distribution
entirely, but whose samples in some way help to compute desired
expectations with respect to the density of interest.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>In fact, drawing multiple independent samples from the
same base set and continuing the computation with all of them is also
useful, and also called resampling. One abstract view of the thing
called a “particle filter” is interleaving resampling steps between
a series of <code>bind</code>s in the <code>Importanter</code> monad.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7"><p>The attentive reader may notice that I am not
passing a count to <code>replicateM</code> here. I mean a combinator that cannot
be defined in Haskell in general, which emits a lazy stream of results
from a monadic action. For samplers this is OK though, because
drawing randomness commutes in distribution:</p>
<pre><code>replicateM :: Sampler a -&gt; Sampler [a]</code></pre>
<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></li>
<li id="fn8"><p>The denominator <span class="math inline">\(s(\texttt{Just } A)\)</span> in this formula is
of course just the probability that <code>xs</code> accepts, that is returns
<code>Just</code> something as opposed to <code>Nothing</code>. We can compute it (to
arbitrarily good approximation) as the expectation of the indicator
function for <span class="math inline">\(\texttt{Just } A\)</span> over <code>xs</code>, but we don’t need to in
practice because <code>rejection</code> builds that correction in for us.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>The distribution over a single element is still <code>join xss</code>, but now they are coupled through the common machine. To reprise
the choice of coins example, a sequence of flips generated by choosing
one coin with unknown bias and flipping it repeatedly is not IID,
because seeing the beginning of the sequence gives information about
the end by learning (something about) the bias of the coin.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>If you wrote <code>exchangeably</code> without the <code>join</code>, it would
produce a sampler for samplers for IID sequences. However, you
wouldn’t know a priori which IID sequence you were going to get, so
predictions about the future behavior of any one of them would be
affected by observations of its past behavior, by inferring the
internal structure of the machine.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
  </div>

  <footer>
    <div class="metadata">
    </div>
    <div class="nav-back">
      <a href="../../../" title>← Conversations index</a>
    </div>
  </footer>
</article>

      </div><!-- #content -->
    </div><!-- #container -->

    <div id="footer">
    </div><!-- #footer -->
  </div><!-- #wrapper .hfeed -->
</body>
</html>
